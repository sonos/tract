// vim: ft=arm

// C tile regs: d8..d16 to preserve, v16 to v31, no need to preserve
//
// v8  v11 v14 v17 v20 v23 v26 v29
// v9  v12 v15 v18 v21 v24 v27 v30
// v10 v13 v16 v19 v22 v25 v28 v31

// no preservation for v0-v7:
// packed A buffering (2x8 values): rotating over v0..v3
// packed B buffering (2x8 values): alternating v4, v5 with v6, v7

.text
.align 4

.cpu generic+fp+simd
.global {{G}}arm64simd_mmm_f32_12x8_{{core}}_{{suffix}}
{{G}}arm64simd_mmm_f32_12x8_{{core}}_{{suffix}}:

/*
    prfm        pldl1keep, [x1]
    prfm        pldl1keep, [x2]
*/

    stp         x20, x21, [sp, #-16]!
    stp         x22, x23, [sp, #-16]!
    stp         x24, x25, [sp, #-16]!
    stp         x26, x27, [sp, #-16]!

    stp         d8, d9, [sp, #-16]!
    stp         d10, d11, [sp, #-16]!
    stp         d12, d13, [sp, #-16]!
    stp         d14, d15, [sp, #-16]!

{% for r in (8..31) %}
    eor         v{{r}}.8b, v{{r}}.8b, v{{r}}.8b
{% endfor %}

    ldp         x7, x8, [x0]        // a, b
    ldp         x9, x10, [x0, #16]  // c, lin

    ldp         x2, x1, [x7]        // a disc, a first arg

    cmp         x2, #1
    bne         .unsupported

    ldp         x5, x3, [x10]       // lin disc, k
    cmp         x5, #0
    bne         .unsupported
    cmp         x3, #0
    beq         .non_linear

    ldp         x4, x2, [x8]        // b disc, first arg
    cmp         x4, #1
    beq         .packed_packed
    cmp         x4, #2
    beq         .packed_tops_and_offsets
    b           .unsupported

.packed_tops_and_offsets:
    ldr         x8, [x8, #16]       // cols ptr ptr (x2 = row offsets ptr)
    ldr         x4, [ x2 ], #8      // fist row offset

    ldp         x20, x21, [x8], #16 // heads of cols ptrs
    ldp         x22, x23, [x8], #16
    ldp         x24, x25, [x8], #16
    ldp         x26, x27, [x8], #16

.p2align 4
.packed_tops_and_offsets_loop_1:
    ld1         { v0.4s, v1.4s, v2.4s }, [ x1 ], #48

    add         x8, x4, x20
    ld1         {v4.s}[0], [ x8 ]
    add         x9, x4, x21
    ld1         {v4.s}[1], [ x9 ]
    add         x10, x4, x22
    ld1         {v4.s}[2], [ x10 ]
    add         x11, x4, x23
    ld1         {v4.s}[3], [ x11 ]
    add         x12, x4, x24
    ld1         {v5.s}[0], [ x12 ]
    add         x13, x4, x25
    ld1         {v5.s}[1], [ x13 ]
    add         x14, x4, x26
    ld1         {v5.s}[2], [ x14 ]
    add         x15, x4, x27
    ld1         {v5.s}[3], [ x15 ]

    ldr         x4, [ x2 ], #8

    {% for col in (0..7) %}
        {% for reg in (0..2) %}
            fmla v{{col | times:3 | plus: 8 | plus: reg}}.4s, v{{reg}}.4s, v{{col| divided_by:4 | plus: 4}}.s[{{col| modulo: 4}}]
        {% endfor %}
    {% endfor %}

    subs        x3, x3, #1
    bne         .packed_tops_and_offsets_loop_1

    b           .non_linear

    subs        x3, x3, #1
    bne .packed_packed_loop_1

    b .non_linear

.packed_packed:
    ld1         { v0.4s, v1.4s, v2.4s }, [ x1 ], #48
    ld1         { v4.4s, v5.4s }, [ x2 ], #32

{% capture packed_packed_loop1 %}
{% if core == "a53" %}
        {% include "arm64simd_mmm_f32_12x8/packed_packed_loop1/ldr_w_preload.tmpli" %}
    {% else %}
        {% include "arm64simd_mmm_f32_12x8/packed_packed_loop1/naive.tmpli" %}
    {% endif %}
{% endcapture %}

    cmp         x3, #4
    blt         .packed_packed_loop_1

.p2align 4
.packed_packed_loop_4:
    {{ packed_packed_loop1 }}
    {{ packed_packed_loop1 }}
    {{ packed_packed_loop1 }}
    {{ packed_packed_loop1 }}

    sub x3, x3, #4
    cmp x3, #4
    bge .packed_packed_loop_4

    cmp x3, #0
    beq .non_linear


.p2align 4
.packed_packed_loop_1:
    {{ packed_packed_loop1 }}
    subs        x3, x3, #1
    bne .packed_packed_loop_1

    b .non_linear

.non_linear:
    ldr         x1, [x0, #32]
    cmp         x1, #0
    bne         .non_linear_loop_entry

.store:
    ldr         x3, [x0, #16]
    ldp         x5, x6, [x3]                // c base ptr, rsc
    ldp         x7, x8, [x3, #16]           // csc, item_size

    cmp         x6, #4
    bne         .store_strides_generic
    cmp         x7, #48
    bne         .store_strides_generic

    {% for col in (0..7) %}
        str q{{col | times:3 | plus: 8 }}, [ x5 ]
        str q{{col | times:3 | plus: 9}}, [ x5, #16 ]
        str q{{col | times:3 | plus: 10}}, [ x5, #32 ]
        add x5, x5, x7
    {% endfor %}

    mov         x0, #0
    b           .return

.store_strides_generic:
    {% for col in (0..7) %}
        mov x4, x5
        {% for reg in (0..2) %}
            {% for lane in (0..3) %}
                st1 { v{{col | times:3 | plus: 8 | plus: reg}}.s }[{{lane}}], [ x4 ], x6
            {% endfor %}
        {% endfor %}
        add x5, x5, x7
    {% endfor %}

    mov         x0, #0
    b           .return

.return:
    ldp         d14, d15, [sp], #16
    ldp         d12, d13, [sp], #16
    ldp         d10, d11, [sp], #16
    ldp         d8, d9, [sp], #16

    ldp         x26, x27, [sp], #16
    ldp         x24, x25, [sp], #16
    ldp         x22, x23, [sp], #16
    ldp         x20, x21, [sp], #16

    ret

.non_linear_loop_entry:
    sub         x1, x1, 40

.non_linear_loop:
    add         x1, x1, 40
    ldr         x2, [x1]
    cmp         x2, #0
    beq         .store
    cmp         x2, #1
    beq         .min
    cmp         x2, #2
    beq         .max
    cmp         x2, #3
    beq         .add_unicast
    cmp         x2, #4
    beq         .per_row_mul
    cmp         x2, #5
    beq         .per_row_add
    cmp         x2, #6
    beq         .per_col_mul
    cmp         x2, #7
    beq         .per_col_add
    cmp         x2, #8
    beq         .add_row_col_product
    cmp         x2, #9
    beq         .scalar_mul
    cmp         x2, #10
    beq         .scalar_add

    add         x0, x2, #4000
    b           .return

.min:
    add         x2, x1, #8
    ld1         {v0.s}[0], [ x2 ]
    dup         v0.4s, v0.s[0]
    {% for reg in (8..31) %}
        fmin        v{{reg}}.4s, v{{reg}}.4s, v0.4s
    {% endfor %}

    b           .non_linear_loop

.max:
    add         x2, x1, #8
    ld1         {v0.s}[0], [ x2 ]
    dup         v0.4s, v0.s[0]
    {% for reg in (8..31) %}
        fmax        v{{reg}}.4s, v{{reg}}.4s, v0.4s
    {% endfor %}

    b           .non_linear_loop

.add_unicast:
    ldp         x5, x6, [x1, #8 ]           // c base ptr, rsc
    ldp         x7, x8, [x1, #24]           // csc, item_size

    {% for col in (0..7) %}
        mov x4, x5
        {% for reg in (0..2) %}
            {% for lane in (0..3) %}
                ld1 {v0.s}[{{lane}}], [ x4 ], x6
            {% endfor %}
            fadd v{{col | times:3 | plus: 8| plus: reg}}.4s, v{{col | times:3 | plus: 8 | plus: reg}}.4s, v0.4s
        {% endfor %}
        add x5, x5, x7
    {% endfor %}

    b           .non_linear_loop

.per_col_mul:
    ldr         x2, [x1, #8]
    ldr         q0, [ x2 ], #16
    ldr         q1, [ x2 ], #16

    {% for col in (0..7) %}
        {% for reg in (0..2) %}
            fmul v{{col | times:3 | plus: reg|plus:8}}.4s, v{{col | times:3 | plus: reg|plus:8}}.4s, v{{col|divided_by:4}}.s[{{col|modulo:4}}]
        {% endfor %}
    {% endfor %}

    b           .non_linear_loop

.per_col_add:
    ldr         x2, [x1, #8]
    ldr         q0, [ x2 ], #16
    ldr         q1, [ x2 ], #16

    {% for col in (0..7) %}
    dup v3.4s, v{{col|divided_by:4}}.s[{{col|modulo:4}}]
        {% for reg in (0..2) %}
            fadd v{{col | times:3 | plus: reg|plus:8}}.4s, v{{col | times:3 | plus: reg|plus:8}}.4s, v3.4s
    {% endfor %}
    {% endfor %}

    b           .non_linear_loop

.per_row_mul:
    ldr         x2, [x1, #8]
    ldr         q0, [ x2 ], #16
    ldr         q1, [ x2 ], #16
    ldr         q2, [ x2 ], #16

    {% for col in (0..7) %}
        {% for reg in (0..2) %}
            fmul v{{col | times:3 | plus: 8 | plus: reg}}.4s, v{{col | times:3 | plus: 8 | plus: reg}}.4s, v{{reg}}.4s
        {% endfor %}
    {% endfor %}

    b           .non_linear_loop

.per_row_add:
    ldr         x2, [x1, #8]
    ldr         q0, [ x2 ], #16
    ldr         q1, [ x2 ], #16
    ldr         q2, [ x2 ], #16

    {% for col in (0..7) %}
        {% for reg in (0..2) %}
            fadd v{{col | times:3 | plus: 8 | plus: reg}}.4s, v{{col | times:3 | plus: 8 | plus: reg}}.4s, v{{reg}}.4s
        {% endfor %}
    {% endfor %}

    b           .non_linear_loop

.add_row_col_product:
    ldr     x2, [x1, #8]
    ldr     x3, [x1, #16]

    ld1         { v0.4s, v1.4s, v2.4s }, [ x2 ]
    ld1         { v4.4s, v5.4s }, [ x3 ]

    {% for col in (0..7) %}
        {% for reg in (0..2) %}
            fmla v{{col | times:3 | plus: 8 | plus: reg}}.4s, v{{reg}}.4s, v{{col| divided_by:4 | plus: 4}}.s[{{col| modulo: 4}}]
        {% endfor %}
    {% endfor %}

    b           .non_linear_loop

.scalar_mul:
    add         x2, x1, #8
    ld1         {v0.s}[0], [ x2 ]
    dup         v0.4s, v0.s[0]
    {% for reg in (8..31) %}
        fmul        v{{reg}}.4s, v{{reg}}.4s, v0.4s
    {% endfor %}

    b           .non_linear_loop

.scalar_add:
    add         x2, x1, #8
    ld1         {v0.s}[0], [ x2 ]
    dup         v0.4s, v0.s[0]
    {% for reg in (8..31) %}
        fadd        v{{reg}}.4s, v{{reg}}.4s, v0.4s
    {% endfor %}

    b           .non_linear_loop

.unsupported:
    mov         x0, #1
    b           .return
